<!doctype html>
<html lang="en">
<head>
<title>Mechanisms of AI Protein Folding in ESMFold</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Mechanistic interpretability analysis of how ESMFold predicts protein structure from sequence" />
<meta property="og:title" content="Mechanisms of AI Protein Folding in ESMFold" />
<meta property="og:description" content="Mechanistic interpretability analysis of how ESMFold predicts protein structure from sequence" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Mechanisms of AI Protein Folding in ESMFold" />
<meta name="twitter:description" content="Mechanistic interpretability analysis of how ESMFold predicts protein structure from sequence" />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<!-- KaTeX for math rendering -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}

/* Green biology theme */
.nd-pageheader {
  background-color: rgb(15, 103, 59) !important;
  color: #ffffff !important;
}
.nd-pageheader h1, .nd-pageheader address {
  color: #fff !important;
}
.nd-pageheader address a {
  color: #fff !important;
  text-decoration: none;
  border-bottom: 1px dashed rgba(255,255,255,0.4);
}
.nd-pageheader address a:hover {
  border-bottom: 1px solid #fff;
}
.nd-pagefooter {
  background-color: rgb(41 227 133 / 55%) !important;
  color: #000 !important;
}
.nd-pagefooter a {
  color: #000 !important;
}

/* Math styling */
.katex { font-size: 1.1em; }
.katex-display { margin: 1em 0; overflow-x: auto; }

/* Citation links */
a.citation-link {
  color: #0066cc;
  text-decoration: none;
}

/* Equation labels */
.equation-label {
  float: right;
  color: #666;
  font-size: 0.9em;
}

/* Stage color coding */
.stage-early { color: #D95F02; }
.stage-late { color: #1B7F3A; }

/* Two-column figure layout */
.row figure {
  margin-bottom: 20px;
}
.row figure figcaption {
  font-size: 0.9em;
  margin-top: 10px;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 Mechanisms of AI Protein Folding in ESMFold
 </h1>
<address>
  <nobr><a href="https://kevinlu4588.github.io/">Kevin Lu</a><sup>1</sup>,</nobr>
  <nobr><a href="https://jannik-brinkmann.github.io/">Jannik Brinkmann</a><sup>1,2</sup>,</nobr>
  <nobr><a href="https://cryoem.hms.harvard.edu/people/stefan-huber">Stefan Huber</a><sup>3</sup>,</nobr>
  <nobr><a href="https://aaronmueller.github.io/">Aaron Mueller</a><sup>4</sup>,</nobr>
  <nobr><a href="https://belinkov.com/">Yonatan Belinkov</a><sup>5</sup>,</nobr>
  <nobr><a href="https://baulab.info/">David Bau</a><sup>1</sup>,</nobr>
  <nobr><a href="https://wendlerc.github.io/">Chris Wendler</a><sup>1</sup></nobr>
 <br>
  <nobr><sup>1</sup>Northeastern University,</nobr>
  <nobr><sup>2</sup>TU Clausthal,</nobr>
  <nobr><sup>3</sup>Harvard University,</nobr>
  <nobr><sup>4</sup>Boston University,</nobr>
  <nobr><sup>5</sup>Technion</nobr>
</address>
 </div> 
</div><!-- end nd-pageheader -->
 
<div class="container">
<div class="row justify-content-center text-center">

<p>
<a href="https://arxiv.org/pdf/2602.06020" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/kevinlu4588/ProteinFolding" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
<a href="https://huggingface.co/datasets/kevinlu4588/ProteinFolding/tree/main" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/huggingface-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Hugging Face dataset thumbnail" data-nothumb=""><br>Dataset<br>Hugging Face</a>
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>How AI Models Fold Proteins?</h3>
<p>
Ever since AlphaFold showed that AI could predict protein structures with atomic accuracy, scientists have asked: how does it actually work? We study this question by opening up ESMFold, a state-of-the-art protein folding model. Our work is the first mechanistic analysis of the folding trunk, the core engine that turns amino acid sequences into 3D structures. We find that the trunk operates in two distinct phases: first assembling a chemical picture of residue interactions, then building the geometric blueprint that determines the final fold. These internal representations are not just interpretable: they can be steered to change the predicted structure.
</p>



</div><!--card-block-->
</div><!--card-->

</div><!--row-->
  
<div class="row">
<div class="col">

    <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/Figure1.png" style="width:80%; max-width:800px"></center>
  <figcaption><strong>Figure 1: Two computational stages in the ESMFold folding trunk.</strong> We identify which latent representations in the model influence hairpin formation by patching activations from a hairpin protein into a helical protein at each block of the trunk, then measuring whether the output folds as a hairpin. <span class="stage-early">Sequence patches (orange)</span> induce hairpin formation in early blocks (0&ndash;7); <span class="stage-late">pairwise patches (green)</span> are effective in late blocks, with results aggregated over 2000 experiments. We show that stage 1 propagates biochemical features (e.g., charge) from sequence into pairwise representations, while stage 2 develops pairwise spatial features (distances, contacts) that modulate sequence attention and control output geometry.</figcaption>
  </figure>

<h3>What is a Protein Structure?</h3>


  To understand our experiments, it helps to understand more about the protein folding task. The input is a sequence of amino acids (20 types like A,R,N,K) which we call "residues" when they are present in a protein. The output is a shape where each atom in a residue is given a precise location and orientation in 3d space, showing how the protein folds. BIologists often visualize a folded protein using a cartoon diagram like this:


  <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/betaHairpin.jpg" style="width:100%; max-width:400px"></center>
  <figcaption><strong>Beta-hairpin structure.</strong> A simple protein motif consisting of two antiparallel beta strands connected by a tight turn. Backbone atoms are shown with hydrogen bonds (dashed lines) stabilizing the sheet structure, and C$_\alpha$&ndash;C$_\alpha$ distances are commonly used to measure inter-residue distances.</figcaption>
  </figure>

  In our experiments we study how the model folds a simple structural motif, the "beta hairpin", which consists of a two strands that form a 180-degree fold, where residues before and after the hairpin join into parallel "beta strands" due to affinities between matching residues on either side.



<h3>What is inside an AI Protein Folding Model?</h3>

<p>
ESMFold <a href="#ref-lin2023" class="citation-link">[Lin et al., 2023]</a> predicts protein structure from sequence alone using a three-module architecture:
</p>

  <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/esmfold_architecture.png" style="width:80%; max-width:800px"></center>
  <figcaption><strong>Figure 1: ESMFold Architecture.</strong> The model consists of (1) ESM-2 language model that embeds the sequence, (2) Folding Trunk that processes sequence and pairwise representations through multiple blocks, and (3) Structure Module that converts pairwise features into 3D coordinates.</figcaption>
  </figure>

<p>
<strong>Module 1: ESM-2 Language Model.</strong> The input sequence is first processed by ESM-2, a 3B-parameter transformer pretrained on 250M protein sequences. ESM-2 produces a contextualized embedding $s_i \in \mathbb{R}^{2560}$ for each residue position $i$, capturing evolutionary and structural patterns learned during pretraining.
</p>

<p>
<strong>Module 2: Folding Trunk.</strong> The core of ESMFold is a folding trunk consisting of 48 stacked blocks. Each block maintains two representations:
</p>

<ul>
<li>Sequence representation $s_i$ (per-residue features)</li>
<li>Pairwise representation $z_{ij}$ (features for each residue pair)</li>
</ul>


<p>
<strong>Attention and Triangular Updates:</strong> Within each block, the sequence representation is updated via self-attention, while the pairwise representation is refined through triangular multiplicative updates (inspired by AlphaFold2) and row/column-based attention. The two representations are also coupled: each block exchanges information between them.

</p>

<p>
<strong>Module 3: Structure Module.</strong> After 48 folding blocks, the final pairwise representation $z_{ij}$ is passed to a structure module that predicts 3D coordinates.
</p>

<h2>When Does the Model Fold a Hairpin?</h2>

<p>
We use activation patching to localize where hairpin formation is computed in the folding trunk. We select a <strong>donor protein</strong> containing a beta hairpin and a <strong>target protein</strong> containing a helix-turn-helix motif. We run both proteins through ESMFold, extracting the sequence representation $s$ and pairwise representation $z$ at each block of the folding trunk. During the target's forward pass, we replace representations in the target's helical region with the donor's hairpin representations, aligning the two regions at their loop positions. We then observe whether the output structure contains a hairpin in the patched region.
</p>

    <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/FigureCActivationPatchingDraft4.png" style="width:100%; max-width:800px"></center>
  <figcaption><strong>Figure 3: Activation Patching Setup.</strong> We run a donor protein containing a beta hairpin through ESMFold and extract the sequence (orange) and pairwise (green) representations of the hairpin region. During the forward pass of a target protein containing a helix-turn-helix motif, we replace the target's representations with the donor's hairpin representations at a single block, then measure if the output contains a hairpin.</figcaption>
  </figure>

<p>
<strong>Single-block patching reveals two regimes (Figure 1).</strong> To localize the computation, we patch at a single block $k$, patching either sequence or pairwise representations alone. Restricting to the ~2,000 cases where full patching succeeded, we measure the success rate for each block and representation type:
</p>

<ul>
<li><span class="stage-early"><strong>Sequence patches</strong> are effective in early blocks (0-7), with success rates peaking around 40% at block 0 and declining thereafter.</span></li>
<li><span class="stage-late"><strong>Pairwise patches</strong> show the opposite pattern: they only become effective starting around block 25, reaching success rates around 20% by block 35.</span></li>
</ul>

<p>
We then investigate two distinct computational mechanisms: <span class="stage-early"> biochemical sequence information flow in early blocks</span>, and <span class="stage-late"> spatial feature formation in late blocks</span>.
</p>

<h2>ESMFold Learns and Uses Representations of Charge</h2>
<p>
We ask whether the model leverages biochemical features to guide folding, and focus on <strong>charge</strong>. Charge is biochemically relevant for hairpin stability: antiparallel beta strands are often stabilized by salt bridges between oppositely charged residues on facing positions.
</p>

  <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/Figure6ChargeBoomDraft4.png" style="width:100%; max-width:800px"></center>
  <figcaption><strong>Figure 5: Electrostatic Complementarity Steering.</strong> (a) We steer the sequence representation toward opposite charges on the two helical regions flanking the loop. (b) Steering in early blocks (0&ndash;10) is most effective at inducing hydrogen bond formation. (c) Control: same-charge steering increases cross-strand distance, opposite-charge steering decreases it.</figcaption>
  </figure>

<p>
<strong>Charge is linearly encoded.</strong> We use a difference-in-means approach to identify a "charge direction" in the sequence representation space. Let $\mathcal{P} = \{\text{K}, \text{R}, \text{H}\}$ denote positively charged residues and $\mathcal{N} = \{\text{D}, \text{E}\}$ denote negatively charged residues. We compute:
</p>

$$v_{\text{charge}} = \frac{\bar{s}_{\mathcal{P}} - \bar{s}_{\mathcal{N}}}{\|\bar{s}_{\mathcal{P}} - \bar{s}_{\mathcal{N}}\|}$$

<p>
Projecting residue representations onto $v_{\text{charge}}$ shows clean separation between charge classes at early blocks, confirming that charge is linearly encoded.
</p>

<p>
<strong>Electrostatic complementarity steering.</strong> Because this direction is linear, we can manipulate it. For a target helix-turn-helix region, we steer one helix toward positive charge and the other toward negative charge, mimicking the electrostatic complementarity of natural hairpins:
</p>

$$s_i' = s_i \pm \alpha \cdot v_{\text{charge}}$$

<p>
<strong>Result:</strong> <span class="stage-early">Complementarity steering induces hydrogen bond formation, with the effect concentrated in early blocks (0&ndash;10).</span> As a control, steering both strands to the same charge increases cross-strand distance (repulsion), while opposite charges decrease it (attraction). This confirms that the charge direction causally influences predicted geometry.
</p>


<figure class="center_image" style="margin-top: 30px">
  <div class="video-widget" style="max-width: 1000px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; background: #000;">
    <video id="attraction-video" muted playsinline preload="auto" style="width: 100%; display: block;">
      <source src="attraction.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="video-controls" style="display: flex; align-items: center; gap: 10px; padding: 8px 12px; background: #f8f8f8; border-top: 1px solid #ddd; font-size: 14px; font-family: 'Open Sans', sans-serif;">
      <button id="attraction-play-btn" onclick="toggleAttractionPlay()" style="border: none; background: none; cursor: pointer; font-size: 18px; padding: 2px 6px; line-height: 1;" title="Play/Pause">&#9654;</button>
      <input id="attraction-scrubber" type="range" min="0" max="1000" value="0" step="1" style="flex: 1; cursor: pointer; accent-color: rgb(15, 103, 59);" oninput="scrubAttraction(this.value)">
      <span id="attraction-time" style="min-width: 70px; text-align: center; color: #555; font-size: 12px;">0:00 / 0:00</span>
      <label style="display: flex; align-items: center; gap: 4px; color: #555; font-size: 12px; margin: 0; cursor: pointer;" title="Loop playback">
        <input id="attraction-loop" type="checkbox" onchange="document.getElementById('attraction-video').loop = this.checked" style="accent-color: rgb(15, 103, 59);"> Loop
      </label>
      <select id="attraction-speed" onchange="document.getElementById('attraction-video').playbackRate = parseFloat(this.value)" style="border: 1px solid #ccc; border-radius: 4px; padding: 2px 4px; font-size: 12px; background: #fff; cursor: pointer;">
        <option value="0.25">0.25x</option>
        <option value="0.5">0.5x</option>
        <option value="1" selected>1x</option>
        <option value="1.5">1.5x</option>
        <option value="2">2x</option>
      </select>
    </div>
  </div>
  <figcaption><strong>Charge attraction animation.</strong> Steering opposite charges toward each other decreases cross-strand distance, demonstrating electrostatic attraction. As magnitude increases, the protein begins to collapse in on itself (possibly due to the level of attraction, or because of out of distribution shifts). </figcaption>
</figure>

<script>
(function() {
  var vid = document.getElementById('attraction-video');
  var btn = document.getElementById('attraction-play-btn');
  var scrubber = document.getElementById('attraction-scrubber');
  var timeDisplay = document.getElementById('attraction-time');
  vid.loop = false;

  function fmt(s) {
    var m = Math.floor(s / 60);
    var sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
  }

  vid.addEventListener('timeupdate', function() {
    if (vid.duration) {
      scrubber.value = (vid.currentTime / vid.duration) * 1000;
      timeDisplay.textContent = fmt(vid.currentTime) + ' / ' + fmt(vid.duration);
    }
  });

  vid.addEventListener('play', function() { btn.innerHTML = '&#9646;&#9646;'; });
  vid.addEventListener('pause', function() { btn.innerHTML = '&#9654;'; });

  window.toggleAttractionPlay = function() {
    if (vid.paused) { vid.play(); } else { vid.pause(); }
  };

  window.scrubAttraction = function(val) {
    if (vid.duration) { vid.currentTime = (val / 1000) * vid.duration; }
  };
})();
</script>

<figure class="center_image" style="margin-top: 30px">
  <div class="video-widget" style="max-width: 1000px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; background: #000;">
    <video id="disruption-video" muted playsinline preload="auto" style="width: 100%; display: block;">
      <source src="disruption.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="video-controls" style="display: flex; align-items: center; gap: 10px; padding: 8px 12px; background: #f8f8f8; border-top: 1px solid #ddd; font-size: 14px; font-family: 'Open Sans', sans-serif;">
      <button id="disruption-play-btn" onclick="toggleDisruptionPlay()" style="border: none; background: none; cursor: pointer; font-size: 18px; padding: 2px 6px; line-height: 1;" title="Play/Pause">&#9654;</button>
      <input id="disruption-scrubber" type="range" min="0" max="1000" value="0" step="1" style="flex: 1; cursor: pointer; accent-color: rgb(15, 103, 59);" oninput="scrubDisruption(this.value)">
      <span id="disruption-time" style="min-width: 70px; text-align: center; color: #555; font-size: 12px;">0:00 / 0:00</span>
      <label style="display: flex; align-items: center; gap: 4px; color: #555; font-size: 12px; margin: 0; cursor: pointer;" title="Loop playback">
        <input id="disruption-loop" type="checkbox" onchange="document.getElementById('disruption-video').loop = this.checked" style="accent-color: rgb(15, 103, 59);"> Loop
      </label>
      <select id="disruption-speed" onchange="document.getElementById('disruption-video').playbackRate = parseFloat(this.value)" style="border: 1px solid #ccc; border-radius: 4px; padding: 2px 4px; font-size: 12px; background: #fff; cursor: pointer;">
        <option value="0.25">0.25x</option>
        <option value="0.5">0.5x</option>
        <option value="1" selected>1x</option>
        <option value="1.5">1.5x</option>
        <option value="2">2x</option>
      </select>
    </div>
  </div>
  <figcaption><strong>Charge disruption animation.</strong> However, applying the “charge direction” to make both strands positive (blue) has the opposite effect: we observe a smooth repulsion effect as the DoM magnitude increases. </figcaption>
</figure>

<script>
(function() {
  var vid = document.getElementById('disruption-video');
  var btn = document.getElementById('disruption-play-btn');
  var scrubber = document.getElementById('disruption-scrubber');
  var timeDisplay = document.getElementById('disruption-time');
  vid.loop = false;

  function fmt(s) {
    var m = Math.floor(s / 60);
    var sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
  }

  vid.addEventListener('timeupdate', function() {
    if (vid.duration) {
      scrubber.value = (vid.currentTime / vid.duration) * 1000;
      timeDisplay.textContent = fmt(vid.currentTime) + ' / ' + fmt(vid.duration);
    }
  });

  vid.addEventListener('play', function() { btn.innerHTML = '&#9646;&#9646;'; });
  vid.addEventListener('pause', function() { btn.innerHTML = '&#9654;'; });

  window.toggleDisruptionPlay = function() {
    if (vid.paused) { vid.play(); } else { vid.pause(); }
  };

  window.scrubDisruption = function(val) {
    if (vid.duration) { vid.currentTime = (val / 1000) * vid.duration; }
  };
})();
</script>


<h3>Manipulating Linear Representations of Residue Distances</h3>

<p>
By the late blocks, sequence patching no longer induces hairpin formation, but pairwise patching does. This suggests that the pairwise representation $z$ has taken over as the primary carrier of folding-relevant information. We hypothesize that $z$ encodes spatial relationships—particularly pairwise distances.
</p>

 <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/Figure7ContactSteeringDraft12.png" style="width:100%; max-width:800px"></center>
  <figcaption><strong>Figure 6: Distance Encoding and Steering.</strong> (a) $R^2$ score of linear distance probes reaches ~0.9 at late blocks. (b) Hydrogen bond formation peaks when steering blocks 20&ndash;35. (c) Steering setup: we steer cross-strand residue pairs toward a target distance of 5.5&Aring;.</figcaption>
  </figure>

<p>
<strong>Distance probing.</strong> We train linear probes to predict pairwise C$_\alpha$ distance from $z$ at each block. Even at block 0, $z$ contains some distance information from positional embeddings. But as $z$ is populated with sequence information and refined through triangular updates, <span class="stage-late">probe accuracy increases substantially, reaching $R^2 \approx 0.9$ by late blocks</span>.
</p>

<p>
<strong>Distance steering.</strong> Since the probe is linear, we can steer toward a target distance (5.5&Aring;, the typical C$_\alpha$&ndash;C$_\alpha$ spacing for cross-strand contacts in beta-sheets) by moving along the probe's weight direction:
</p>

$$z'_{ij} = z_{ij} - \alpha \cdot \mathbf{w}$$

<p>
<strong>Result:</strong> <span class="stage-late">Steering in blocks 20&ndash;35 is most effective, with hydrogen bond formation peaking around 40%.</span> Steering in early blocks is less effective both because probes are less accurate and because subsequent computation can overwrite the perturbation. This confirms that late $z$ causally determines geometric outputs.
</p>

<figure class="center_image" style="margin-top: 30px">
  <div class="video-widget" style="max-width: 1000px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; background: #000;">
    <video id="indcloser-video" muted playsinline preload="auto" style="width: 100%; display: block;">
      <source src="ind_closer.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="video-controls" style="display: flex; align-items: center; gap: 10px; padding: 8px 12px; background: #f8f8f8; border-top: 1px solid #ddd; font-size: 14px; font-family: 'Open Sans', sans-serif;">
      <button id="indcloser-play-btn" onclick="toggleIndcloserPlay()" style="border: none; background: none; cursor: pointer; font-size: 18px; padding: 2px 6px; line-height: 1;" title="Play/Pause">&#9654;</button>
      <input id="indcloser-scrubber" type="range" min="0" max="1000" value="0" step="1" style="flex: 1; cursor: pointer; accent-color: rgb(15, 103, 59);" oninput="scrubIndcloser(this.value)">
      <span id="indcloser-time" style="min-width: 70px; text-align: center; color: #555; font-size: 12px;">0:00 / 0:00</span>
      <label style="display: flex; align-items: center; gap: 4px; color: #555; font-size: 12px; margin: 0; cursor: pointer;" title="Loop playback">
        <input id="indcloser-loop" type="checkbox" onchange="document.getElementById('indcloser-video').loop = this.checked" style="accent-color: rgb(15, 103, 59);"> Loop
      </label>
      <select id="indcloser-speed" onchange="document.getElementById('indcloser-video').playbackRate = parseFloat(this.value)" style="border: 1px solid #ccc; border-radius: 4px; padding: 2px 4px; font-size: 12px; background: #fff; cursor: pointer;">
        <option value="0.25">0.25x</option>
        <option value="0.5">0.5x</option>
        <option value="1" selected>1x</option>
        <option value="1.5">1.5x</option>
        <option value="2">2x</option>
      </select>
    </div>
  </div>
  <figcaption><strong>Distance steering: inducing closer contacts.</strong> Steering cross-strand residue pairs toward a target distance of 5.5&Aring; induces hydrogen bond formation in late blocks.</figcaption>
</figure>

<script>
(function() {
  var vid = document.getElementById('indcloser-video');
  var btn = document.getElementById('indcloser-play-btn');
  var scrubber = document.getElementById('indcloser-scrubber');
  var timeDisplay = document.getElementById('indcloser-time');
  vid.loop = false;

  function fmt(s) {
    var m = Math.floor(s / 60);
    var sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
  }

  vid.addEventListener('timeupdate', function() {
    if (vid.duration) {
      scrubber.value = (vid.currentTime / vid.duration) * 1000;
      timeDisplay.textContent = fmt(vid.currentTime) + ' / ' + fmt(vid.duration);
    }
  });

  vid.addEventListener('play', function() { btn.innerHTML = '&#9646;&#9646;'; });
  vid.addEventListener('pause', function() { btn.innerHTML = '&#9654;'; });

  window.toggleIndcloserPlay = function() {
    if (vid.paused) { vid.play(); } else { vid.pause(); }
  };

  window.scrubIndcloser = function(val) {
    if (vid.duration) { vid.currentTime = (val / 1000) * vid.duration; }
  };
})();
</script>

<figure class="center_image" style="margin-top: 30px">
  <div class="video-widget" style="max-width: 1000px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; background: #000;">
    <video id="repfarther-video" muted playsinline preload="auto" style="width: 100%; display: block;">
      <source src="rep_farther.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="video-controls" style="display: flex; align-items: center; gap: 10px; padding: 8px 12px; background: #f8f8f8; border-top: 1px solid #ddd; font-size: 14px; font-family: 'Open Sans', sans-serif;">
      <button id="repfarther-play-btn" onclick="toggleRepfartherPlay()" style="border: none; background: none; cursor: pointer; font-size: 18px; padding: 2px 6px; line-height: 1;" title="Play/Pause">&#9654;</button>
      <input id="repfarther-scrubber" type="range" min="0" max="1000" value="0" step="1" style="flex: 1; cursor: pointer; accent-color: rgb(15, 103, 59);" oninput="scrubRepfarther(this.value)">
      <span id="repfarther-time" style="min-width: 70px; text-align: center; color: #555; font-size: 12px;">0:00 / 0:00</span>
      <label style="display: flex; align-items: center; gap: 4px; color: #555; font-size: 12px; margin: 0; cursor: pointer;" title="Loop playback">
        <input id="repfarther-loop" type="checkbox" onchange="document.getElementById('repfarther-video').loop = this.checked" style="accent-color: rgb(15, 103, 59);"> Loop
      </label>
      <select id="repfarther-speed" onchange="document.getElementById('repfarther-video').playbackRate = parseFloat(this.value)" style="border: 1px solid #ccc; border-radius: 4px; padding: 2px 4px; font-size: 12px; background: #fff; cursor: pointer;">
        <option value="0.25">0.25x</option>
        <option value="0.5">0.5x</option>
        <option value="1" selected>1x</option>
        <option value="1.5">1.5x</option>
        <option value="2">2x</option>
      </select>
    </div>
  </div>
  <figcaption><strong>Distance steering: repelling farther apart.</strong> Steering cross-strand residue pairs toward a larger target distance pushes strands apart, serving as a control for the distance steering experiment.</figcaption>
</figure>

<script>
(function() {
  var vid = document.getElementById('repfarther-video');
  var btn = document.getElementById('repfarther-play-btn');
  var scrubber = document.getElementById('repfarther-scrubber');
  var timeDisplay = document.getElementById('repfarther-time');
  vid.loop = false;

  function fmt(s) {
    var m = Math.floor(s / 60);
    var sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
  }

  vid.addEventListener('timeupdate', function() {
    if (vid.duration) {
      scrubber.value = (vid.currentTime / vid.duration) * 1000;
      timeDisplay.textContent = fmt(vid.currentTime) + ' / ' + fmt(vid.duration);
    }
  });

  vid.addEventListener('play', function() { btn.innerHTML = '&#9646;&#9646;'; });
  vid.addEventListener('pause', function() { btn.innerHTML = '&#9654;'; });

  window.toggleRepfartherPlay = function() {
    if (vid.paused) { vid.play(); } else { vid.pause(); }
  };

  window.scrubRepfarther = function(val) {
    if (vid.duration) { vid.currentTime = (val / 1000) * vid.duration; }
  };
})();
</script>

<h3>Pair2Seq Promotes Contact Information</h3>

<p>
How does distance information in $z$ influence the rest of the computation? The pair2seq pathway projects $z$ to produce a scalar bias that modulates sequence self-attention.
</p>
  <figure class="center_image" style="margin-top: 30px;">
    <center><img src="images/paper/Figure4Wide.png" style="width:100%; max-width:900px"></center>
    <figcaption><strong>Figure 7: Pair2Seq Bias and Patching Effects.</strong> (a) ROC-AUC for classifying contacts (C$_\alpha$ &lt; 8&Aring;) vs. non-contacts using bias values alone. The pair2seq bias cleanly separates contacts in middle and late blocks. (b) Heatmap of attention bias values (red = positive, blue = negative) with green contours showing residue pairs within 8&Aring;. (c) After patching $z$, attention shifts toward donor contacts and away from target contacts. (d) Ablating the pair2seq bias after patching results in minor drops in hairpin formation.</figcaption>
  </figure>

<p>
<strong>Bias encodes contacts.</strong> In middle and late blocks, the pair2seq bias cleanly separates contacting residue pairs (C$_\alpha$ distance &lt; 8&Aring;) from non-contacts. <span class="stage-late">Residue pairs in contact receive substantially more positive bias than non-contacts</span>, encouraging the sequence attention to preferentially mix information between contacting residues. We visualize the bias values across blocks in the <a href="#appendix-bias-maps">Appendix</a>, along with per-head biases which show distinct patterns and suggest head specialization as an area for future investigation.
</p>

<p>
<strong>Causal role.</strong> We tested this by patching the pairwise representation at block 27 and measuring how sequence attention changes. <span class="stage-late">After patching, attention to donor-unique contacts increases substantially (up to 400%), while attention to target-unique contacts decreases.</span> The pairwise representation causally redirects which residues attend to each other.
</p>

<h3>The Structure Module Uses Z as a Distance Map</h3>

<p>
The pair2seq pathway is one route by which $z$ influences the output. But $z$ also feeds directly into the structure module, which produces the final 3D coordinates.
</p>

  <figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/Figure5StructureModuleScalingDraft12.png" style="width:100%; max-width:700px"></center>
  <figcaption><strong>Figure 8: Structure Module Scaling Experiment.</strong> (a) Effect of scaling $z$ versus $s$ on mean pairwise C$_\alpha$ distance. Scaling $z$ monotonically scales the output structure; scaling $s$ has virtually no effect. (b) Example structures at different pairwise scaling factors.</figcaption>
  </figure>

<p>
<strong>Scaling experiment.</strong> We scaled the pairwise representation by factors ranging from 0 to 2 before it enters the structure module, while holding $s$ fixed. We then repeated the experiment scaling $s$ while holding $z$ fixed.
</p>

<p>
<strong>Result:</strong> <span class="stage-late">Scaling $z$ monotonically scales the mean pairwise distance between residues in the output structure.</span> Scaling up causes the protein to expand; scaling down causes it to contract. In contrast, scaling $s$ has virtually no effect on output geometry. Together with our steering experiments, this confirms that $z$ acts as a geometric blueprint that the structure module renders into 3D coordinates.
</p>
<figure class="center_image" style="margin-top: 30px">
  <div class="video-widget" style="max-width: 1000px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; background: #000;">
    <video id="zsweep-video" muted playsinline preload="auto" style="width: 100%; display: block;">
      <source src="z_sweep.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="video-controls" style="display: flex; align-items: center; gap: 10px; padding: 8px 12px; background: #f8f8f8; border-top: 1px solid #ddd; font-size: 14px; font-family: 'Open Sans', sans-serif;">
      <button id="zsweep-play-btn" onclick="toggleZsweepPlay()" style="border: none; background: none; cursor: pointer; font-size: 18px; padding: 2px 6px; line-height: 1;" title="Play/Pause">&#9654;</button>
      <input id="zsweep-scrubber" type="range" min="0" max="1000" value="0" step="1" style="flex: 1; cursor: pointer; accent-color: rgb(15, 103, 59);" oninput="scrubZsweep(this.value)">
      <span id="zsweep-time" style="min-width: 70px; text-align: center; color: #555; font-size: 12px;">0:00 / 0:00</span>
      <label style="display: flex; align-items: center; gap: 4px; color: #555; font-size: 12px; margin: 0; cursor: pointer;" title="Loop playback">
        <input id="zsweep-loop" type="checkbox" onchange="document.getElementById('zsweep-video').loop = this.checked" style="accent-color: rgb(15, 103, 59);"> Loop
      </label>
      <select id="zsweep-speed" onchange="document.getElementById('zsweep-video').playbackRate = parseFloat(this.value)" style="border: 1px solid #ccc; border-radius: 4px; padding: 2px 4px; font-size: 12px; background: #fff; cursor: pointer;">
        <option value="0.25">0.25x</option>
        <option value="0.5">0.5x</option>
        <option value="1" selected>1x</option>
        <option value="1.5">1.5x</option>
        <option value="2">2x</option>
      </select>
    </div>
  </div>
  <figcaption><strong>Pairwise scaling animation.</strong> Sweeping the pairwise representation scaling factor from 0 to 2 shows the protein expanding and contracting, confirming that $z$ acts as a geometric blueprint for the output structure.</figcaption>
</figure>

<script>
(function() {
  var vid = document.getElementById('zsweep-video');
  var btn = document.getElementById('zsweep-play-btn');
  var scrubber = document.getElementById('zsweep-scrubber');
  var timeDisplay = document.getElementById('zsweep-time');
  vid.loop = false;

  function fmt(s) {
    var m = Math.floor(s / 60);
    var sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
  }

  vid.addEventListener('timeupdate', function() {
    if (vid.duration) {
      scrubber.value = (vid.currentTime / vid.duration) * 1000;
      timeDisplay.textContent = fmt(vid.currentTime) + ' / ' + fmt(vid.duration);
    }
  });

  vid.addEventListener('play', function() { btn.innerHTML = '&#9646;&#9646;'; });
  vid.addEventListener('pause', function() { btn.innerHTML = '&#9654;'; });

  window.toggleZsweepPlay = function() {
    if (vid.paused) { vid.play(); } else { vid.pause(); }
  };

  window.scrubZsweep = function(val) {
    if (vid.duration) { vid.currentTime = (val / 1000) * vid.duration; }
  };
})();
</script>

<h2>References</h2>

<div id="ref-anfinsen1973" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Anfinsen, C. B. (1973). Principles that govern the folding of protein chains. <em>Science</em>, 181(4096), 223-230.
</p>
</div>

<div id="ref-jumper2021" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., ... & Hassabis, D. (2021). Highly accurate protein structure prediction with AlphaFold. <em>Nature</em>, 596(7873), 583-589.
</p>
</div>

<div id="ref-lin2023" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Lin, Z., Akin, H., Rao, R., Hie, B., Zhu, Z., Lu, W., ... & Rives, A. (2023). Evolutionary-scale prediction of atomic-level protein structure with a language model. <em>Science</em>, 379(6637), 1123-1130.
</p>
</div>

<div id="ref-olah2020" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Olah, C., Cammarata, N., Schubert, L., Goh, G., Petrov, M., & Carter, S. (2020). Zoom in: An introduction to circuits. <em>Distill</em>, 5(3), e00024-001.
</p>
</div>

<div id="ref-meng2022" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Meng, K., Bau, D., Andonian, A., & Belinkov, Y. (2022). Locating and editing factual associations in GPT. <em>Advances in Neural Information Processing Systems</em>, 35, 17359-17372.
</p>
</div>

<div id="ref-vig2020" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Vig, J., Madani, A., Varshney, L. R., Xiong, C., Socher, R., & Rajani, N. F. (2020). BERTology meets biology: Interpreting attention in protein language models. <em>arXiv preprint arXiv:2006.15222</em>.
</p>
</div>

<div id="ref-wang2022" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Wang, K., Variengien, A., Conmy, A., Shlegeris, B., & Steinhardt, J. (2022). Interpretability in the wild: a circuit for indirect object identification in GPT-2 small. <em>arXiv preprint arXiv:2211.00593</em>.
</p>
</div>

<div id="ref-munoz1997" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Muñoz, V., Thompson, P. A., Hofrichter, J., & Eaton, W. A. (1997). Folding dynamics and mechanism of β-hairpin formation. <em>Nature</em>, 390(6656), 196-199.
</p>
</div>

<div id="ref-dill2008" class="cite">
<p style="text-indent: -3em; margin-left: 3em;">
Dill, K. A., Ozkan, S. B., Shell, M. S., & Weikl, T. R. (2008). The protein folding problem. <em>Annual Review of Biophysics</em>, 37, 289-316.
</p>
</div>

<h2>How to cite</h2>

<p>The paper can be cited as follows.</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Lu, K., Brinkmann, J., Huber, S., Mueller, A., Belinkov, Y., Bau, D., &amp; Wendler, C. (2026). Mechanisms of AI Protein Folding in ESMFold. <em>arXiv preprint arXiv:2602.06020</em>.
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
@article{lu2026mechanisms,
  title={Mechanisms of AI Protein Folding in ESMFold},
  author={Lu, Kevin and Brinkmann, Jannik and Huber, Stefan and Mueller, Aaron and Belinkov, Yonatan and Bau, David and Wendler, Chris},
  journal={arXiv preprint arXiv:2602.06020},
  year={2026}
}
</pre>
</div>
</div>


<h2 id="appendix-bias-maps">Appendix: Bias Maps</h2>

<p>
We visualize the pair2seq attention bias across blocks and across individual attention heads. For a single protein (PDB: 6rwc), we extract the bias term $\beta_{ij}(z_{ij})$ and average over heads. Green contours indicate structural contacts (C$_\alpha$ distance &lt; 8&Aring;).
</p>

<h3>Bias Across Blocks (Head-Averaged)</h3>

<p>
Each panel shows the bias term $\beta_{ij}$, averaged across all 8 attention heads, for protein 6rwc at selected blocks of the folding trunk. Red indicates positive bias (encouraging attention); blue indicates negative bias. In early blocks, the bias is near-uniform; by the middle blocks, it begins to align with the contact map, and by late blocks, contacting residue pairs receive substantially higher bias than non-contacts.
</p>

<div class="row">
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block00_avg.png" style="width:100%"><p class="text-center"><small>Block 0</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block04_avg.png" style="width:100%"><p class="text-center"><small>Block 4</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block08_avg.png" style="width:100%"><p class="text-center"><small>Block 8</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block12_avg.png" style="width:100%"><p class="text-center"><small>Block 12</small></p></div>
</div>
<div class="row">
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block16_avg.png" style="width:100%"><p class="text-center"><small>Block 16</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block20_avg.png" style="width:100%"><p class="text-center"><small>Block 20</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block24_avg.png" style="width:100%"><p class="text-center"><small>Block 24</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block28_avg.png" style="width:100%"><p class="text-center"><small>Block 28</small></p></div>
</div>
<div class="row">
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_avg.png" style="width:100%"><p class="text-center"><small>Block 32</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block36_avg.png" style="width:100%"><p class="text-center"><small>Block 36</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block40_avg.png" style="width:100%"><p class="text-center"><small>Block 40</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block44_avg.png" style="width:100%"><p class="text-center"><small>Block 44</small></p></div>
</div>

<h3>Per-Head Bias at Block 32</h3>

<p>
Individual attention head bias values for protein 6rwc at block 32. Different heads exhibit distinct patterns: some heads show strong contact-aligned bias, while others capture different spatial relationships or show more diffuse patterns. This specialization suggests that individual heads attend to complementary aspects of pairwise geometry.
</p>

<div class="row">
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head0.png" style="width:100%"><p class="text-center"><small>Head 0</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head1.png" style="width:100%"><p class="text-center"><small>Head 1</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head2.png" style="width:100%"><p class="text-center"><small>Head 2</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head3.png" style="width:100%"><p class="text-center"><small>Head 3</small></p></div>
</div>
<div class="row" style="margin-bottom: 30px;">
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head4.png" style="width:100%"><p class="text-center"><small>Head 4</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head5.png" style="width:100%"><p class="text-center"><small>Head 5</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head6.png" style="width:100%"><p class="text-center"><small>Head 6</small></p></div>
  <div class="col-md-3 col-sm-6"><img src="images/paper/bias_maps/6rwc_block32_head7.png" style="width:100%"><p class="text-center"><small>Head 7</small></p></div>
</div>


</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
// KaTeX auto-render initialization
document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false}
    ],
    throwOnError: false
  });
});

// Clickselect for citations
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
</script>
</html>

